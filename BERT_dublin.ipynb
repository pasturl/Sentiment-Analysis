{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_dublin.ipynb","provenance":[{"file_id":"1xwJ2MSwHEXXh6wD7t0AdLc1iLmxdrapN","timestamp":1628271852293}],"collapsed_sections":[],"mount_file_id":"1cF_qPTyOuh5Nmosz0SyrLc_Nhd6cvu-Z","authorship_tag":"ABX9TyMscr2Prj1fcIwf/I2A4JKu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdPgP28phRW7","executionInfo":{"status":"ok","timestamp":1628271910901,"user_tz":-120,"elapsed":17752,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"b5dbd8dd-2660-477c-8d0b-fe35bf1a51d6"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UyLt-gvaf9s5","executionInfo":{"status":"ok","timestamp":1628271911821,"user_tz":-120,"elapsed":925,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"4bc216b0-7bb9-4e1d-9ae3-bdc65f59e078"},"source":["!git clone https://github.com/vonsovsky/bert-sentiment.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'bert-sentiment'...\n","remote: Enumerating objects: 38, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 38 (delta 16), reused 27 (delta 11), pack-reused 0\u001b[K\n","Unpacking objects: 100% (38/38), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rmZco00g01r","executionInfo":{"status":"ok","timestamp":1628271918483,"user_tz":-120,"elapsed":6665,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"1357449e-fc1d-4e13-feb0-1511ebc4aa7a"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 66.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 51.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 22.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAVbPnlTf_G8","executionInfo":{"status":"ok","timestamp":1628271918483,"user_tz":-120,"elapsed":6,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"dd60c7b9-b99d-4a79-c3fd-7fe2d48e78d9"},"source":["%cd bert-sentiment/"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/bert-sentiment\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cz7_q4lZgCYS","executionInfo":{"status":"ok","timestamp":1628273907250,"user_tz":-120,"elapsed":230,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["import re\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn import metrics\n","\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","from torch.utils.data import RandomSampler\n","from tqdm import tqdm, trange\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers import BertConfig, BertForSequenceClassification, BertTokenizer"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezg1V1o9gizo","executionInfo":{"status":"ok","timestamp":1628272585599,"user_tz":-120,"elapsed":334,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["PAD_TOKEN_LABEL_ID = CrossEntropyLoss().ignore_index\n","\n","BATCH_SIZE = 16\n","LEARNING_RATE_MODEL = 1e-5\n","LEARNING_RATE_CLASSIFIER = 1e-3\n","WARMUP_STEPS = 0\n","GRADIENT_ACCUMULATION_STEPS = 1\n","MAX_GRAD_NORM = 1.0\n","SEED = 42\n","NO_CUDA = False"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOyr7hMgp-Gs","executionInfo":{"status":"ok","timestamp":1628273384581,"user_tz":-120,"elapsed":213,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["filename = \"/content/drive/MyDrive/bert/citypulse.dublin_city_council.test.csv\"\n","\n","data, y_hat = read_dublin_data(filename)\n"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"aoUIZN4GkzLP"},"source":["# col_names = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n","# df_train = pd.read_csv(\"/content/drive/MyDrive/data/Sentiment140-train.csv\", encoding=\"latin-1\", header = None, names = col_names)\n","# df_test = pd.read_csv(\"/content/drive/MyDrive/data/Sentiment140-test.csv\", encoding=\"latin-1\", header = None, names = col_names)\n","# df_dublin = pd.read_csv(\"/content/drive/MyDrive/data/citypulse.dublin_city_council.test.csv\", encoding=\"latin-1\" )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWLPJyVLg5WC","executionInfo":{"status":"ok","timestamp":1628273167610,"user_tz":-120,"elapsed":216,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["def rpad(array, n):\n","    current_len = len(array)\n","    if current_len > n:\n","        return array[:n]\n","    extra = n - current_len\n","    return array + ([0] * extra)\n","\n","\n","def convert_to_embedding(tokenizer, sentences_with_labels):\n","    for sentence, label in sentences_with_labels:\n","        tokens = tokenizer.tokenize(sentence)\n","        tokens = tokens[:250]\n","        bert_sent = rpad(tokenizer.convert_tokens_to_ids([\"CLS\"] + tokens + [\"SEP\"]), n=256)\n","        yield torch.tensor(bert_sent), torch.tensor(label, dtype=torch.int64)\n","\n","\n","def parse_line(line):\n","    line = line.strip().lower()\n","    line = line.replace(\"&nbsp;\", \" \")\n","    line = re.sub(r'<br(\\s\\/)?>', ' ', line)\n","    line = re.sub(r' +', ' ', line)  # merge multiple spaces into one\n","\n","    return line\n","\n","\n","def convert_sentiment_dublin(x):\n","    if x == \"neutral\":\n","        return -1\n","    elif x == \"negative\":\n","        return 0\n","    else:\n","        return 1\n","\n","\n","def read_imdb_data(filename):\n","    data = []\n","    for line in open(filename, 'r', encoding=\"utf-8\"):\n","        data.append(parse_line(line))\n","\n","    return data\n","\n","\n","def read_dublin_data(filename):\n","    data = []\n","    df = pd.read_csv(filename, encoding=\"latin-1\" )\n","    df['sentiment'] = df['sentiment'].apply(convert_sentiment_dublin)\n","    data = list(df['text'].values)\n","    y = np.zeros(len(df))\n","    y = df['sentiment'].values\n","    return data, y\n","\n","\n","def prepare_dataloader(tokenizer, sampler=RandomSampler, train=False):\n","    #filename = \"/content/drive/MyDrive/bert/Sentiment140-train.csv\" if train else \"/content/drive/MyDrive/bert/Sentiment140-test.csv\"\n","    filename = \"/content/drive/MyDrive/bert/citypulse.dublin_city_council.test.csv\"\n","\n","    data, y = read_dublin_data(filename)\n","    \n","    sentences_with_labels = zip(data, y.tolist())\n","\n","    dataset = list(convert_to_embedding(tokenizer, sentences_with_labels))\n","\n","    sampler_func = sampler(dataset) if sampler is not None else None\n","    dataloader = DataLoader(dataset, sampler=sampler_func, batch_size=BATCH_SIZE)\n","\n","    return dataloader"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"73ebcmWTg7Na","executionInfo":{"status":"ok","timestamp":1628273553011,"user_tz":-120,"elapsed":211,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["class Transformers:\n","    model = None\n","\n","    def __init__(self, tokenizer):\n","        self.pad_token_label_id = PAD_TOKEN_LABEL_ID\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and not NO_CUDA else \"cpu\")\n","        self.tokenizer = tokenizer\n","\n","    def predict(self, sentence):\n","        if self.model is None or self.tokenizer is None:\n","            self.load()\n","\n","        embeddings = list(convert_to_embedding([(sentence, -1)]))\n","        preds = self._predict_tags_batched(embeddings)\n","        return preds\n","\n","    def evaluate(self, dataloader):\n","        from sklearn.metrics import classification_report\n","        y_pred = self._predict_tags_batched(dataloader)\n","        y_true = np.zeros(len(y_hat))\n","        #y_true = y_hat\n","\n","        score = classification_report(y_true, y_pred)\n","        print(score)\n","        return y_true, y_pred\n","\n","    def _predict_tags_batched(self, dataloader):\n","        preds = []\n","        self.model.eval()\n","        for batch in tqdm(dataloader, desc=\"Computing NER tags\"):\n","            batch = tuple(t.to(self.device) for t in batch)\n","\n","            with torch.no_grad():\n","                outputs = self.model(batch[0])\n","                _, is_neg = torch.max(outputs[0], 1)\n","                preds.extend(is_neg.cpu().detach().numpy())\n","\n","        return preds\n","\n","    def train(self, dataloader, model, epochs):\n","        assert self.model is None  # make sure we are not training after load() command\n","        model.to(self.device)\n","        self.model = model\n","\n","        t_total = len(dataloader) // GRADIENT_ACCUMULATION_STEPS * epochs\n","\n","        # Prepare optimizer and schedule (linear warmup and decay)\n","        optimizer_grouped_parameters = [\n","            {\"params\": model.bert.parameters(), \"lr\": LEARNING_RATE_MODEL},\n","            {\"params\": model.classifier.parameters(), \"lr\": LEARNING_RATE_CLASSIFIER}\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=t_total)\n","\n","        # Train!\n","        print(\"***** Running training *****\")\n","        print(\"Training on %d examples\", len(dataloader))\n","        print(\"Num Epochs = %d\", epochs)\n","        print(\"Total optimization steps = %d\", t_total)\n","\n","        global_step = 0\n","        tr_loss, logging_loss = 0.0, 0.0\n","        model.zero_grad()\n","        train_iterator = trange(epochs, desc=\"Epoch\")\n","        self._set_seed()\n","        for _ in train_iterator:\n","            epoch_iterator = tqdm(dataloader, desc=\"Iteration\")\n","            for step, batch in enumerate(epoch_iterator):\n","                model.train()\n","                batch = tuple(t.to(self.device) for t in batch)\n","                outputs = model(batch[0], labels=batch[1])\n","                loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n","\n","                if GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / GRADIENT_ACCUMULATION_STEPS\n","\n","                loss.backward()\n","\n","                tr_loss += loss.item()\n","                if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n","\n","                    scheduler.step()  # Update learning rate schedule\n","                    optimizer.step()\n","                    model.zero_grad()\n","                    global_step += 1\n","\n","        self.model = model\n","\n","        return global_step, tr_loss / global_step\n","\n","    def _set_seed(self):\n","        torch.manual_seed(SEED)\n","        if self.device == 'gpu':\n","            torch.cuda.manual_seed_all(SEED)\n","\n","    def load(self, model_dir='weights/'):\n","        self.tokenizer = BertTokenizer.from_pretrained(model_dir)\n","        self.model = BertForSequenceClassification.from_pretrained(model_dir)\n","        self.model.to(self.device)"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3Rt1kdTg9_d","executionInfo":{"status":"ok","timestamp":1628273756905,"user_tz":-120,"elapsed":45834,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"1c794ce2-27b1-49c3-fe97-51ac9878cc66"},"source":["def train(epochs=20, output_dir=\"weights/\"):\n","    num_labels = 2  # negative and positive reviews\n","    config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n","\n","    dataloader = prepare_dataloader(tokenizer, train=True)\n","    predictor = Transformers(tokenizer)\n","    predictor.train(dataloader, model, epochs)\n","\n","    model.save_pretrained(output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","\n","def evaluate(model_dir=\"weights/\"):\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","    dataloader = prepare_dataloader(tokenizer, train=False, sampler=None)\n","    predictor = Transformers(tokenizer)\n","    predictor.load(model_dir=model_dir)\n","    y_true, y_pred = predictor.evaluate(dataloader)\n","    return y_true, y_pred\n","\n","\n","\n","path = '/content/drive/MyDrive/bert/weights/'\n","#os.makedirs(path, exist_ok=True)\n","#train(epochs=10, output_dir=path)\n","y_true, y_pred = evaluate(model_dir=path)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Computing NER tags:  18%|█▊        | 33/188 [00:09<00:44,  3.45it/s]\u001b[A\n","Computing NER tags:  18%|█▊        | 34/188 [00:09<00:44,  3.46it/s]\u001b[A\n","Computing NER tags:  19%|█▊        | 35/188 [00:10<00:44,  3.45it/s]\u001b[A\n","Computing NER tags:  19%|█▉        | 36/188 [00:10<00:44,  3.44it/s]\u001b[A\n","Computing NER tags:  20%|█▉        | 37/188 [00:10<00:43,  3.45it/s]\u001b[A\n","Computing NER tags:  20%|██        | 38/188 [00:11<00:43,  3.43it/s]\u001b[A\n","Computing NER tags:  21%|██        | 39/188 [00:11<00:43,  3.41it/s]\u001b[A\n","Computing NER tags:  21%|██▏       | 40/188 [00:11<00:44,  3.35it/s]\u001b[A\n","Computing NER tags:  22%|██▏       | 41/188 [00:11<00:43,  3.38it/s]\u001b[A\n","Computing NER tags:  22%|██▏       | 42/188 [00:12<00:43,  3.39it/s]\u001b[A\n","Computing NER tags:  23%|██▎       | 43/188 [00:12<00:42,  3.39it/s]\u001b[A\n","Computing NER tags:  23%|██▎       | 44/188 [00:12<00:42,  3.38it/s]\u001b[A\n","Computing NER tags:  24%|██▍       | 45/188 [00:13<00:42,  3.40it/s]\u001b[A\n","Computing NER tags:  24%|██▍       | 46/188 [00:13<00:41,  3.39it/s]\u001b[A\n","Computing NER tags:  25%|██▌       | 47/188 [00:13<00:41,  3.38it/s]\u001b[A\n","Computing NER tags:  26%|██▌       | 48/188 [00:14<00:41,  3.36it/s]\u001b[A\n","Computing NER tags:  26%|██▌       | 49/188 [00:14<00:41,  3.37it/s]\u001b[A\n","Computing NER tags:  27%|██▋       | 50/188 [00:14<00:40,  3.38it/s]\u001b[A\n","Computing NER tags:  27%|██▋       | 51/188 [00:14<00:40,  3.38it/s]\u001b[A\n","Computing NER tags:  28%|██▊       | 52/188 [00:15<00:40,  3.37it/s]\u001b[A\n","Computing NER tags:  28%|██▊       | 53/188 [00:15<00:39,  3.38it/s]\u001b[A\n","Computing NER tags:  29%|██▊       | 54/188 [00:15<00:39,  3.36it/s]\u001b[A\n","Computing NER tags:  29%|██▉       | 55/188 [00:16<00:39,  3.35it/s]\u001b[A\n","Computing NER tags:  30%|██▉       | 56/188 [00:16<00:39,  3.36it/s]\u001b[A\n","Computing NER tags:  30%|███       | 57/188 [00:16<00:39,  3.35it/s]\u001b[A\n","Computing NER tags:  31%|███       | 58/188 [00:17<00:38,  3.36it/s]\u001b[A\n","Computing NER tags:  31%|███▏      | 59/188 [00:17<00:38,  3.36it/s]\u001b[A\n","Computing NER tags:  32%|███▏      | 60/188 [00:17<00:38,  3.36it/s]\u001b[A\n","Computing NER tags:  32%|███▏      | 61/188 [00:17<00:37,  3.37it/s]\u001b[A\n","Computing NER tags:  33%|███▎      | 62/188 [00:18<00:37,  3.37it/s]\u001b[A\n","Computing NER tags:  34%|███▎      | 63/188 [00:18<00:37,  3.37it/s]\u001b[A\n","Computing NER tags:  34%|███▍      | 64/188 [00:18<00:36,  3.39it/s]\u001b[A\n","Computing NER tags:  35%|███▍      | 65/188 [00:19<00:36,  3.38it/s]\u001b[A\n","Computing NER tags:  35%|███▌      | 66/188 [00:19<00:36,  3.36it/s]\u001b[A\n","Computing NER tags:  36%|███▌      | 67/188 [00:19<00:36,  3.35it/s]\u001b[A\n","Computing NER tags:  36%|███▌      | 68/188 [00:19<00:35,  3.35it/s]\u001b[A\n","Computing NER tags:  37%|███▋      | 69/188 [00:20<00:35,  3.35it/s]\u001b[A\n","Computing NER tags:  37%|███▋      | 70/188 [00:20<00:35,  3.35it/s]\u001b[A\n","Computing NER tags:  38%|███▊      | 71/188 [00:20<00:35,  3.33it/s]\u001b[A\n","Computing NER tags:  38%|███▊      | 72/188 [00:21<00:35,  3.31it/s]\u001b[A\n","Computing NER tags:  39%|███▉      | 73/188 [00:21<00:34,  3.32it/s]\u001b[A\n","Computing NER tags:  39%|███▉      | 74/188 [00:21<00:34,  3.33it/s]\u001b[A\n","Computing NER tags:  40%|███▉      | 75/188 [00:22<00:33,  3.33it/s]\u001b[A\n","Computing NER tags:  40%|████      | 76/188 [00:22<00:33,  3.32it/s]\u001b[A\n","Computing NER tags:  41%|████      | 77/188 [00:22<00:33,  3.34it/s]\u001b[A\n","Computing NER tags:  41%|████▏     | 78/188 [00:23<00:33,  3.33it/s]\u001b[A\n","Computing NER tags:  42%|████▏     | 79/188 [00:23<00:32,  3.32it/s]\u001b[A\n","Computing NER tags:  43%|████▎     | 80/188 [00:23<00:32,  3.32it/s]\u001b[A\n","Computing NER tags:  43%|████▎     | 81/188 [00:23<00:32,  3.33it/s]\u001b[A\n","Computing NER tags:  44%|████▎     | 82/188 [00:24<00:31,  3.34it/s]\u001b[A\n","Computing NER tags:  44%|████▍     | 83/188 [00:24<00:31,  3.33it/s]\u001b[A\n","Computing NER tags:  45%|████▍     | 84/188 [00:24<00:31,  3.28it/s]\u001b[A\n","Computing NER tags:  45%|████▌     | 85/188 [00:25<00:31,  3.30it/s]\u001b[A\n","Computing NER tags:  46%|████▌     | 86/188 [00:25<00:30,  3.31it/s]\u001b[A\n","Computing NER tags:  46%|████▋     | 87/188 [00:25<00:30,  3.31it/s]\u001b[A\n","Computing NER tags:  47%|████▋     | 88/188 [00:26<00:30,  3.31it/s]\u001b[A\n","Computing NER tags:  47%|████▋     | 89/188 [00:26<00:30,  3.29it/s]\u001b[A\n","Computing NER tags:  48%|████▊     | 90/188 [00:26<00:29,  3.31it/s]\u001b[A\n","Computing NER tags:  48%|████▊     | 91/188 [00:26<00:29,  3.33it/s]\u001b[A\n","Computing NER tags:  49%|████▉     | 92/188 [00:27<00:28,  3.33it/s]\u001b[A\n","Computing NER tags:  49%|████▉     | 93/188 [00:27<00:28,  3.35it/s]\u001b[A\n","Computing NER tags:  50%|█████     | 94/188 [00:27<00:28,  3.36it/s]\u001b[A\n","Computing NER tags:  51%|█████     | 95/188 [00:28<00:27,  3.35it/s]\u001b[A\n","Computing NER tags:  51%|█████     | 96/188 [00:28<00:27,  3.34it/s]\u001b[A\n","Computing NER tags:  52%|█████▏    | 97/188 [00:28<00:27,  3.34it/s]\u001b[A\n","Computing NER tags:  52%|█████▏    | 98/188 [00:29<00:26,  3.34it/s]\u001b[A\n","Computing NER tags:  53%|█████▎    | 99/188 [00:29<00:26,  3.35it/s]\u001b[A\n","Computing NER tags:  53%|█████▎    | 100/188 [00:29<00:26,  3.35it/s]\u001b[A\n","Computing NER tags:  54%|█████▎    | 101/188 [00:29<00:25,  3.36it/s]\u001b[A\n","Computing NER tags:  54%|█████▍    | 102/188 [00:30<00:25,  3.36it/s]\u001b[A\n","Computing NER tags:  55%|█████▍    | 103/188 [00:30<00:25,  3.36it/s]\u001b[A\n","Computing NER tags:  55%|█████▌    | 104/188 [00:30<00:25,  3.34it/s]\u001b[A\n","Computing NER tags:  56%|█████▌    | 105/188 [00:31<00:24,  3.34it/s]\u001b[A\n","Computing NER tags:  56%|█████▋    | 106/188 [00:31<00:24,  3.36it/s]\u001b[A\n","Computing NER tags:  57%|█████▋    | 107/188 [00:31<00:24,  3.34it/s]\u001b[A\n","Computing NER tags:  57%|█████▋    | 108/188 [00:31<00:23,  3.34it/s]\u001b[A\n","Computing NER tags:  58%|█████▊    | 109/188 [00:32<00:23,  3.33it/s]\u001b[A\n","Computing NER tags:  59%|█████▊    | 110/188 [00:32<00:23,  3.35it/s]\u001b[A\n","Computing NER tags:  59%|█████▉    | 111/188 [00:32<00:23,  3.33it/s]\u001b[A\n","Computing NER tags:  60%|█████▉    | 112/188 [00:33<00:22,  3.34it/s]\u001b[A\n","Computing NER tags:  60%|██████    | 113/188 [00:33<00:22,  3.34it/s]\u001b[A\n","Computing NER tags:  61%|██████    | 114/188 [00:33<00:22,  3.33it/s]\u001b[A\n","Computing NER tags:  61%|██████    | 115/188 [00:34<00:21,  3.32it/s]\u001b[A\n","Computing NER tags:  62%|██████▏   | 116/188 [00:34<00:21,  3.34it/s]\u001b[A\n","Computing NER tags:  62%|██████▏   | 117/188 [00:34<00:21,  3.34it/s]\u001b[A\n","Computing NER tags:  63%|██████▎   | 118/188 [00:34<00:20,  3.35it/s]\u001b[A\n","Computing NER tags:  63%|██████▎   | 119/188 [00:35<00:20,  3.36it/s]\u001b[A\n","Computing NER tags:  64%|██████▍   | 120/188 [00:35<00:20,  3.37it/s]\u001b[A\n","Computing NER tags:  64%|██████▍   | 121/188 [00:35<00:19,  3.37it/s]\u001b[A\n","Computing NER tags:  65%|██████▍   | 122/188 [00:36<00:19,  3.36it/s]\u001b[A\n","Computing NER tags:  65%|██████▌   | 123/188 [00:36<00:19,  3.37it/s]\u001b[A\n","Computing NER tags:  66%|██████▌   | 124/188 [00:36<00:18,  3.37it/s]\u001b[A\n","Computing NER tags:  66%|██████▋   | 125/188 [00:37<00:18,  3.36it/s]\u001b[A\n","Computing NER tags:  67%|██████▋   | 126/188 [00:37<00:18,  3.36it/s]\u001b[A\n","Computing NER tags:  68%|██████▊   | 127/188 [00:37<00:18,  3.30it/s]\u001b[A\n","Computing NER tags:  68%|██████▊   | 128/188 [00:37<00:18,  3.32it/s]\u001b[A\n","Computing NER tags:  69%|██████▊   | 129/188 [00:38<00:17,  3.33it/s]\u001b[A\n","Computing NER tags:  69%|██████▉   | 130/188 [00:38<00:17,  3.33it/s]\u001b[A\n","Computing NER tags:  70%|██████▉   | 131/188 [00:38<00:17,  3.32it/s]\u001b[A\n","Computing NER tags:  70%|███████   | 132/188 [00:39<00:16,  3.34it/s]\u001b[A\n","Computing NER tags:  71%|███████   | 133/188 [00:39<00:16,  3.33it/s]\u001b[A\n","Computing NER tags:  71%|███████▏  | 134/188 [00:39<00:16,  3.33it/s]\u001b[A\n","Computing NER tags:  72%|███████▏  | 135/188 [00:40<00:15,  3.34it/s]\u001b[A\n","Computing NER tags:  72%|███████▏  | 136/188 [00:40<00:15,  3.35it/s]\u001b[A\n","Computing NER tags:  73%|███████▎  | 137/188 [00:40<00:15,  3.35it/s]\u001b[A\n","Computing NER tags:  73%|███████▎  | 138/188 [00:40<00:14,  3.35it/s]\u001b[A\n","Computing NER tags:  74%|███████▍  | 139/188 [00:41<00:14,  3.33it/s]\u001b[A\n","Computing NER tags:  74%|███████▍  | 140/188 [00:41<00:14,  3.37it/s]\u001b[A\n","Computing NER tags:  75%|███████▌  | 141/188 [00:41<00:13,  3.38it/s]\u001b[A\n","Computing NER tags:  76%|███████▌  | 142/188 [00:42<00:13,  3.39it/s]\u001b[A\n","Computing NER tags:  76%|███████▌  | 143/188 [00:42<00:13,  3.36it/s]\u001b[A\n","Computing NER tags:  77%|███████▋  | 144/188 [00:42<00:13,  3.38it/s]\u001b[A\n","Computing NER tags:  77%|███████▋  | 145/188 [00:43<00:12,  3.38it/s]\u001b[A\n","Computing NER tags:  78%|███████▊  | 146/188 [00:43<00:12,  3.40it/s]\u001b[A\n","Computing NER tags:  78%|███████▊  | 147/188 [00:43<00:12,  3.42it/s]\u001b[A\n","Computing NER tags:  79%|███████▊  | 148/188 [00:43<00:11,  3.44it/s]\u001b[A\n","Computing NER tags:  79%|███████▉  | 149/188 [00:44<00:11,  3.44it/s]\u001b[A\n","Computing NER tags:  80%|███████▉  | 150/188 [00:44<00:11,  3.39it/s]\u001b[A\n","Computing NER tags:  80%|████████  | 151/188 [00:44<00:10,  3.39it/s]\u001b[A\n","Computing NER tags:  81%|████████  | 152/188 [00:45<00:10,  3.41it/s]\u001b[A\n","Computing NER tags:  81%|████████▏ | 153/188 [00:45<00:10,  3.41it/s]\u001b[A\n","Computing NER tags:  82%|████████▏ | 154/188 [00:45<00:10,  3.38it/s]\u001b[A\n","Computing NER tags:  82%|████████▏ | 155/188 [00:45<00:09,  3.40it/s]\u001b[A\n","Computing NER tags:  83%|████████▎ | 156/188 [00:46<00:09,  3.41it/s]\u001b[A\n","Computing NER tags:  84%|████████▎ | 157/188 [00:46<00:09,  3.41it/s]\u001b[A\n","Computing NER tags:  84%|████████▍ | 158/188 [00:46<00:08,  3.45it/s]\u001b[A\n","Computing NER tags:  85%|████████▍ | 159/188 [00:47<00:08,  3.43it/s]\u001b[A\n","Computing NER tags:  85%|████████▌ | 160/188 [00:47<00:08,  3.42it/s]\u001b[A\n","Computing NER tags:  86%|████████▌ | 161/188 [00:47<00:07,  3.46it/s]\u001b[A\n","Computing NER tags:  86%|████████▌ | 162/188 [00:48<00:07,  3.45it/s]\u001b[A\n","Computing NER tags:  87%|████████▋ | 163/188 [00:48<00:07,  3.43it/s]\u001b[A\n","Computing NER tags:  87%|████████▋ | 164/188 [00:48<00:06,  3.43it/s]\u001b[A\n","Computing NER tags:  88%|████████▊ | 165/188 [00:48<00:06,  3.46it/s]\u001b[A\n","Computing NER tags:  88%|████████▊ | 166/188 [00:49<00:06,  3.46it/s]\u001b[A\n","Computing NER tags:  89%|████████▉ | 167/188 [00:49<00:06,  3.46it/s]\u001b[A\n","Computing NER tags:  89%|████████▉ | 168/188 [00:49<00:05,  3.49it/s]\u001b[A\n","Computing NER tags:  90%|████████▉ | 169/188 [00:50<00:05,  3.49it/s]\u001b[A\n","Computing NER tags:  90%|█████████ | 170/188 [00:50<00:05,  3.49it/s]\u001b[A\n","Computing NER tags:  91%|█████████ | 171/188 [00:50<00:04,  3.45it/s]\u001b[A\n","Computing NER tags:  91%|█████████▏| 172/188 [00:50<00:04,  3.47it/s]\u001b[A\n","Computing NER tags:  92%|█████████▏| 173/188 [00:51<00:04,  3.46it/s]\u001b[A\n","Computing NER tags:  93%|█████████▎| 174/188 [00:51<00:04,  3.46it/s]\u001b[A\n","Computing NER tags:  93%|█████████▎| 175/188 [00:51<00:03,  3.47it/s]\u001b[A\n","Computing NER tags:  94%|█████████▎| 176/188 [00:52<00:03,  3.46it/s]\u001b[A\n","Computing NER tags:  94%|█████████▍| 177/188 [00:52<00:03,  3.42it/s]\u001b[A\n","Computing NER tags:  95%|█████████▍| 178/188 [00:52<00:02,  3.40it/s]\u001b[A\n","Computing NER tags:  95%|█████████▌| 179/188 [00:52<00:02,  3.43it/s]\u001b[A\n","Computing NER tags:  96%|█████████▌| 180/188 [00:53<00:02,  3.42it/s]\u001b[A\n","Computing NER tags:  96%|█████████▋| 181/188 [00:53<00:02,  3.44it/s]\u001b[A\n","Computing NER tags:  97%|█████████▋| 182/188 [00:53<00:01,  3.44it/s]\u001b[A\n","Computing NER tags:  97%|█████████▋| 183/188 [00:54<00:01,  3.44it/s]\u001b[A\n","Computing NER tags:  98%|█████████▊| 184/188 [00:54<00:01,  3.45it/s]\u001b[A\n","Computing NER tags:  98%|█████████▊| 185/188 [00:54<00:00,  3.43it/s]\u001b[A\n","Computing NER tags:  99%|█████████▉| 186/188 [00:54<00:00,  3.44it/s]\u001b[A\n","Computing NER tags:  99%|█████████▉| 187/188 [00:55<00:00,  3.44it/s]\u001b[A\n","Computing NER tags: 100%|██████████| 188/188 [00:55<00:00,  3.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.85      0.92      3000\n","         1.0       0.00      0.00      0.00         0\n","\n","    accuracy                           0.85      3000\n","   macro avg       0.50      0.43      0.46      3000\n","weighted avg       1.00      0.85      0.92      3000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMxEB2F7r8Qm","executionInfo":{"status":"ok","timestamp":1628274189199,"user_tz":-120,"elapsed":208,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"86942d78-fa05-4362-d9f8-7010a28b0415"},"source":["y_pred_bi = np.array(y_pred)[np.in1d(y_hat, [0,1])]\n","y_hat_bi = np.array(y_hat)[np.in1d(y_hat, [0,1])]\n","print(metrics.confusion_matrix(y_hat_bi, y_pred_bi))\n","print(metrics.classification_report(y_hat_bi, y_pred_bi))\n","print(\"Accuracy Score: %.3f\" % metrics.accuracy_score(y_hat_bi, y_pred_bi))"],"execution_count":83,"outputs":[{"output_type":"stream","text":["[[805 195]\n"," [897 103]]\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.81      0.60      1000\n","           1       0.35      0.10      0.16      1000\n","\n","    accuracy                           0.45      2000\n","   macro avg       0.41      0.45      0.38      2000\n","weighted avg       0.41      0.45      0.38      2000\n","\n","Accuracy Score: 0.454\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i3MpB6L4ryw-"},"source":[""],"execution_count":null,"outputs":[]}]}