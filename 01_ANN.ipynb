{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"01_ANN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"weekly-things"},"source":["# https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"],"id":"weekly-things","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqKn2M-_hxo5","executionInfo":{"status":"ok","timestamp":1628184735317,"user_tz":-120,"elapsed":7491,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["%%capture\n","! pip install shap\n","! pip install transformers"],"id":"bqKn2M-_hxo5","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXaYyBf3lbPc","executionInfo":{"status":"ok","timestamp":1628188580595,"user_tz":-120,"elapsed":223,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"61e6c46e-3791-46f2-9387-af250ec5e0ad"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"OXaYyBf3lbPc","execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"db4ef901-1b0f-49b1-99d8-d28e912d5061","executionInfo":{"status":"ok","timestamp":1628188597299,"user_tz":-120,"elapsed":16370,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn import metrics\n","import shap\n","\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from transformers import InputExample, InputFeatures\n","\n","from modules.utils import *\n","import tensorflow as tf"],"id":"db4ef901-1b0f-49b1-99d8-d28e912d5061","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"46ce3b30-9efd-4240-8007-948ed03cb708","executionInfo":{"status":"ok","timestamp":1628188606661,"user_tz":-120,"elapsed":9363,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["col_names = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n","df_train = pd.read_csv(\"/content/drive/MyDrive/data/Sentiment140-train.csv\", encoding=\"latin-1\", header = None, names = col_names)\n","df_test = pd.read_csv(\"/content/drive/MyDrive/data/Sentiment140-test.csv\", encoding=\"latin-1\", header = None, names = col_names)\n","df_dublin = pd.read_csv(\"/content/drive/MyDrive/data/citypulse.dublin_city_council.test.csv\", encoding=\"latin-1\" )"],"id":"46ce3b30-9efd-4240-8007-948ed03cb708","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3342ea3-968d-43b6-bcab-fb1bfab5b7ef","executionInfo":{"status":"ok","timestamp":1628188607001,"user_tz":-120,"elapsed":342,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["df_train['split'] = \"train\"\n","df_test['split'] = \"test\"\n","df_all = pd.concat([df_train, df_test])"],"id":"a3342ea3-968d-43b6-bcab-fb1bfab5b7ef","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"peripheral-doubt","executionInfo":{"status":"ok","timestamp":1628188607001,"user_tz":-120,"elapsed":2,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["df_train = df_train[:10000].reset_index(drop=True)"],"id":"peripheral-doubt","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c17f100-4fca-4082-b3c6-4deacac49c3a","executionInfo":{"status":"ok","timestamp":1628188607845,"user_tz":-120,"elapsed":846,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["df_all['sentiment'] = df_all['sentiment'].apply(convert_sentiment)\n","df_dublin['sentiment'] = df_dublin['sentiment'].apply(convert_sentiment_dublin)"],"id":"1c17f100-4fca-4082-b3c6-4deacac49c3a","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68c7d6b5-b085-4e79-931a-53edb99cc23b","executionInfo":{"status":"ok","timestamp":1628188624595,"user_tz":-120,"elapsed":16752,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"1d646ed4-9cc9-4b24-8d81-9f32ebbf0b86"},"source":["model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"],"id":"68c7d6b5-b085-4e79-931a-53edb99cc23b","execution_count":7,"outputs":[{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57f8a849-9409-4440-98cc-f57d5cf21b21","executionInfo":{"status":"ok","timestamp":1628188624600,"user_tz":-120,"elapsed":9,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"15f33748-715d-4d80-bf2a-561a4ce555f8"},"source":["model.summary()"],"id":"57f8a849-9409-4440-98cc-f57d5cf21b21","execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_for_sequence_classification\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  109482240 \n","_________________________________________________________________\n","dropout_37 (Dropout)         multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  1538      \n","=================================================================\n","Total params: 109,483,778\n","Trainable params: 109,483,778\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dimensional-trunk","executionInfo":{"status":"ok","timestamp":1628188624600,"user_tz":-120,"elapsed":7,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["#df_train['text_decode'] = df_train['text'].str.decode(\"utf-8\")\n","#df_test['text_decode'] = df_test['text'].str.decode(\"utf-8\")"],"id":"dimensional-trunk","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"antique-fabric","executionInfo":{"status":"ok","timestamp":1628188624601,"user_tz":-120,"elapsed":8,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n","    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n","                                                          text_a = x[DATA_COLUMN], \n","                                                          text_b = None,\n","                                                          label = x[LABEL_COLUMN]), axis = 1)\n","\n","    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n","                                                          text_a = x[DATA_COLUMN], \n","                                                          text_b = None,\n","                                                          label = x[LABEL_COLUMN]), axis = 1)\n","\n","    return train_InputExamples, validation_InputExamples\n","\n","def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n","    features = [] # -> will hold InputFeatures to be converted later\n","\n","    for e in examples:\n","        # Documentation is really strong for this method, so please take a look at it\n","        input_dict = tokenizer.encode_plus(\n","            e.text_a,\n","            add_special_tokens=True,\n","            max_length=max_length, # truncates if len(s) > max_length\n","            return_token_type_ids=True,\n","            return_attention_mask=True,\n","            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n","            truncation=True\n","        )\n","\n","        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n","            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n","\n","        features.append(\n","            InputFeatures(\n","                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n","            )\n","        )\n","\n","    def gen():\n","        for f in features:\n","            yield (\n","                {\n","                    \"input_ids\": f.input_ids,\n","                    \"attention_mask\": f.attention_mask,\n","                    \"token_type_ids\": f.token_type_ids,\n","                },\n","                f.label,\n","            )\n","\n","    return tf.data.Dataset.from_generator(\n","        gen,\n","        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n","        (\n","            {\n","                \"input_ids\": tf.TensorShape([None]),\n","                \"attention_mask\": tf.TensorShape([None]),\n","                \"token_type_ids\": tf.TensorShape([None]),\n","            },\n","            tf.TensorShape([]),\n","        ),\n","    )\n","\n","\n","DATA_COLUMN = 'text'\n","LABEL_COLUMN = 'sentiment'"],"id":"antique-fabric","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olympic-tuition","executionInfo":{"status":"ok","timestamp":1628188630961,"user_tz":-120,"elapsed":6367,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"68a10c2b-e737-4a0a-8d51-8fdb145a915f"},"source":["train_InputExamples, validation_InputExamples = convert_data_to_examples(df_train, df_test, DATA_COLUMN, LABEL_COLUMN)\n","\n","train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n","train_data = train_data.shuffle(100).batch(128).repeat(2)\n","\n","validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n","validation_data = validation_data.batch(128)"],"id":"olympic-tuition","execution_count":11,"outputs":[{"output_type":"stream","text":["The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zp9mX86EE6t","executionInfo":{"status":"ok","timestamp":1628188630964,"user_tz":-120,"elapsed":7,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"0da73301-58f9-42f6-b551-2fba6474f29f"},"source":["len(df_dublin)"],"id":"3zp9mX86EE6t","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3000"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"dFiDC3tL5re6","executionInfo":{"status":"ok","timestamp":1628188630964,"user_tz":-120,"elapsed":5,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["#df_sample = df_dublin[:128].reset_index(drop=True)"],"id":"dFiDC3tL5re6","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3LQehlOworB","executionInfo":{"status":"ok","timestamp":1628188630965,"user_tz":-120,"elapsed":5,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":[""],"id":"h3LQehlOworB","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flAXNEPtwWCo","executionInfo":{"status":"ok","timestamp":1628188634862,"user_tz":-120,"elapsed":3902,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"7ae0c5e7-4a08-4bbb-9c4c-c7ce9d928726"},"source":["dublin_InputExamples = df_dublin.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n","                                                      text_a = x[DATA_COLUMN], \n","                                                      text_b = None,\n","                                                      label = x[LABEL_COLUMN]), axis = 1)\n","\n","dublin_data = convert_examples_to_tf_dataset(list(dublin_InputExamples), tokenizer)\n","dublin_data = dublin_data.batch(128)"],"id":"flAXNEPtwWCo","execution_count":14,"outputs":[{"output_type":"stream","text":["The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFZK-0xgxIy5","executionInfo":{"status":"ok","timestamp":1628188476766,"user_tz":-120,"elapsed":1141228,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"338ee616-3bdc-4bc8-8155-098937fdfa95"},"source":["#predictions_bert = model.predict(dublin_data)"],"id":"LFZK-0xgxIy5","execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f135d9b3e50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f135d9b3e50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f1378b67170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f1378b67170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYkIPlotK0gL","executionInfo":{"status":"ok","timestamp":1628188476768,"user_tz":-120,"elapsed":24,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"feab50d9-e957-4c9f-81bc-d028db6128e5"},"source":["#predictions_bert"],"id":"DYkIPlotK0gL","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TFSequenceClassifierOutput([('logits', array([[-0.4306022 , -0.12708119],\n","                                    [-0.37862143, -0.12721029],\n","                                    [-0.40378064, -0.15274249],\n","                                    ...,\n","                                    [-0.40356782, -0.25548655],\n","                                    [-0.37640423, -0.14789182],\n","                                    [-0.402286  , -0.17748238]], dtype=float32))])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"EUGLaUJw7-3F","executionInfo":{"status":"ok","timestamp":1628188476769,"user_tz":-120,"elapsed":18,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["# tf_predictions = tf.nn.softmax(predictions_bert[0], axis=-1)\n","\n","# label = tf.argmax(tf_predictions, axis=1)\n","# label = label.numpy()"],"id":"EUGLaUJw7-3F","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHp_y2u48GIE","executionInfo":{"status":"ok","timestamp":1628188476769,"user_tz":-120,"elapsed":16,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}}},"source":["# df_dublin['sentiment_pred'] = label"],"id":"NHp_y2u48GIE","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIkpwMQyKZ4t","executionInfo":{"status":"ok","timestamp":1628188476770,"user_tz":-120,"elapsed":17,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"eec44c83-14fe-4f34-df70-4dea60b9bf68"},"source":["# df_dublin['sentiment_pred'].value_counts()"],"id":"PIkpwMQyKZ4t","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    2966\n","0      34\n","Name: sentiment_pred, dtype: int64"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ia1Co298JPt","executionInfo":{"status":"ok","timestamp":1628188476770,"user_tz":-120,"elapsed":14,"user":{"displayName":"Lucas Pastur Romay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_t88O1YkfKS1m-zSfNs9FakuWRQmV3C9DLuiGXg=s64","userId":"08212788615723811728"}},"outputId":"0a5ead95-a2f6-46cb-dafc-f8815b44f516"},"source":["# y_hat = df_dublin[\"sentiment\"]\n","# y_pred = df_dublin[\"sentiment_pred\"]\n","# print(metrics.confusion_matrix(y_hat, y_pred))\n","# print(metrics.classification_report(y_hat, y_pred))\n","# print(\"Accuracy Score: %.3f\" % metrics.accuracy_score(y_hat, y_pred))"],"id":"6Ia1Co298JPt","execution_count":21,"outputs":[{"output_type":"stream","text":["[[  0   6 994]\n"," [  0  20 980]\n"," [  0   8 992]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.00      0.00      0.00      1000\n","           0       0.59      0.02      0.04      1000\n","           1       0.33      0.99      0.50      1000\n","\n","    accuracy                           0.34      3000\n","   macro avg       0.31      0.34      0.18      3000\n","weighted avg       0.31      0.34      0.18      3000\n","\n","Accuracy Score: 0.337\n"],"name":"stdout"},{"output_type":"stream","text":["Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adult-publisher","outputId":"c6f38b42-305b-427c-f0b8-fb2eb164e312"},"source":["model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n","\n","model.fit(train_data, epochs=1, validation_data=validation_data)"],"id":"adult-publisher","execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2883e98e50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2883e98e50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f289f04c170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f289f04c170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zz__nnPasYvV"},"source":["predictions_bert = model.predict(dublin_data)"],"id":"Zz__nnPasYvV","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqPMEJsvXwEK"},"source":["tf_predictions = tf.nn.softmax(predictions_bert[0], axis=-1)\n","\n","label = tf.argmax(tf_predictions, axis=1)\n","label = label.numpy()"],"id":"PqPMEJsvXwEK","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSoCSd3cXxwh"},"source":["df_dublin['sentiment_pred_train'] = label"],"id":"KSoCSd3cXxwh","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxakKpuSYJil"},"source":["y_hat = df_dublin[\"sentiment\"]\n","y_pred = df_dublin[\"sentiment_pred_train\"]\n","print(metrics.confusion_matrix(y_hat, y_pred))\n","print(metrics.classification_report(y_hat, y_pred))\n","print(\"Accuracy Score: %.3f\" % metrics.accuracy_score(y_hat, y_pred))"],"id":"SxakKpuSYJil","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19KyGK6tYMop"},"source":[""],"id":"19KyGK6tYMop","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sixth-calcium"},"source":["for i in range(len(pred_sentences)):\n","  print(pred_sentences[i], \": \\n\", labels[label[i]])"],"id":"sixth-calcium","execution_count":null,"outputs":[]}]}